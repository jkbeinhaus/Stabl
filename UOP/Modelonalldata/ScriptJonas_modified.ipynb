{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from scipy.stats import zscore\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'stabl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)\n",
      "\u001b[0;32m/var/folders/yw/jrjtbzm57tbfg8vxk7g41v9h0000gp/T/ipykernel_52502/553181099.py\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLasso\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mstabl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstabl\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStabl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_stabl_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_fdr_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_stabl_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexport_stabl_to_csv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstabl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLowInfoFilter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_low_info_samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'stabl'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.base import clone\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "from stabl.stabl import Stabl, plot_stabl_path, plot_fdr_graph, save_stabl_results, export_stabl_to_csv\n",
    "from stabl.preprocessing import LowInfoFilter, remove_low_info_samples\n",
    "\n",
    "%config InlineBackend.figure_formats=['retina']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stabl.multi_omic_pipelines import multi_omic_stabl, multi_omic_stabl_cv, late_fusion_lasso_cv\n",
    "from stabl.single_omic_pipelines import single_omic_stabl, single_omic_stabl_cv\n",
    "from stabl.pipelines_utils import compute_features_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../DataValidation/Val_celldensities.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/yw/jrjtbzm57tbfg8vxk7g41v9h0000gp/T/ipykernel_24340/2017780085.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mVal_Celldensities\u001b[0m \u001b[0;34m=\u001b[0m     \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../DataValidation/Val_celldensities.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mVal_Function\u001b[0m \u001b[0;34m=\u001b[0m          \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../DataValidation/Val_functional.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mVal_Metavariables\u001b[0m \u001b[0;34m=\u001b[0m     \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../DataValidation/Val_metavariables.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mVal_Neighborhood\u001b[0m \u001b[0;34m=\u001b[0m      \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../DataValidation/Val_neighborhood.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m             \u001b[0;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[1;32m   1218\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    787\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    790\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../DataValidation/Val_celldensities.csv'"
     ]
    }
   ],
   "source": [
    "Val_Celldensities =     pd.read_csv('../DataValidation/Val_celldensities.csv', index_col=0)\n",
    "Val_Function =          pd.read_csv('../DataValidation/Val_functional.csv', index_col=0)\n",
    "Val_Metavariables =     pd.read_csv('../DataValidation/Val_metavariables.csv', index_col=0)\n",
    "Val_Neighborhood =      pd.read_csv('../DataValidation/Val_neighborhood.csv', index_col=0)\n",
    "\n",
    "val_data = {\n",
    "    'Val_Celldensities': Val_Celldensities,\n",
    "    'Val_Function': Val_Function,\n",
    "    'Val_Metavariables': Val_Metavariables,\n",
    "    'Val_Neighborhood': Val_Neighborhood\n",
    "}\n",
    "\n",
    "for data_name, data_frame in val_data.items():\n",
    "    numeric_columns = data_frame.select_dtypes(include=['float64', 'int64']).columns\n",
    "    val_data[data_name][numeric_columns] = val_data[data_name][numeric_columns].apply(zscore)\n",
    "\n",
    "Val_y = pd.read_csv('../DataValidation/Val_outcome.csv',index_col=0)\n",
    "Val_y['site'] = 'Stanford'\n",
    "#Val_y = Val_y.grade-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UOP_Celldensities =     pd.read_csv('../DataTraining/UOPfinal_celldensities.csv', index_col=0)\n",
    "UOP_Function =          pd.read_csv('../DataTraining/UOPfinal_functional.csv', index_col=0)\n",
    "UOP_Metavariables =     pd.read_csv('../DataTraining/UOPfinal_metavariables.csv', index_col=0)\n",
    "UOP_Neighborhood =      pd.read_csv('../DataTraining/UOPfinal_neighborhood.csv', index_col=0)\n",
    "\n",
    "UOP_data = {\n",
    "    'UOP_Celldensities': UOP_Celldensities,\n",
    "    'UOP_Function': UOP_Function,\n",
    "    'UOP_Metavariables': UOP_Metavariables,\n",
    "    'UOP_Neighborhood': UOP_Neighborhood\n",
    "}\n",
    "\n",
    "for data_name, data_frame in UOP_data.items():\n",
    "    numeric_columns = data_frame.select_dtypes(include=['float64', 'int64']).columns\n",
    "    UOP_data[data_name][numeric_columns] = UOP_data[data_name][numeric_columns].apply(zscore)\n",
    "\n",
    "UOP_y = pd.read_csv('../DataTraining/UOPfinal_outcome.csv',index_col=0)\n",
    "UOP_y['site'] = 'UOP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grade</th>\n",
       "      <th>site</th>\n",
       "      <th>patient_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>S01_1</th>\n",
       "      <td>1</td>\n",
       "      <td>Stanford</td>\n",
       "      <td>S01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S01_2</th>\n",
       "      <td>1</td>\n",
       "      <td>Stanford</td>\n",
       "      <td>S01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S01_3</th>\n",
       "      <td>1</td>\n",
       "      <td>Stanford</td>\n",
       "      <td>S01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S02_1</th>\n",
       "      <td>1</td>\n",
       "      <td>Stanford</td>\n",
       "      <td>S02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S02_2</th>\n",
       "      <td>1</td>\n",
       "      <td>Stanford</td>\n",
       "      <td>S02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OC27_002</th>\n",
       "      <td>1</td>\n",
       "      <td>UOP</td>\n",
       "      <td>OC27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OC27_003</th>\n",
       "      <td>1</td>\n",
       "      <td>UOP</td>\n",
       "      <td>OC27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OC28_001</th>\n",
       "      <td>1</td>\n",
       "      <td>UOP</td>\n",
       "      <td>OC28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OC28_002</th>\n",
       "      <td>1</td>\n",
       "      <td>UOP</td>\n",
       "      <td>OC28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OC28_003</th>\n",
       "      <td>1</td>\n",
       "      <td>UOP</td>\n",
       "      <td>OC28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>142 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          grade      site patient_id\n",
       "S01_1         1  Stanford        S01\n",
       "S01_2         1  Stanford        S01\n",
       "S01_3         1  Stanford        S01\n",
       "S02_1         1  Stanford        S02\n",
       "S02_2         1  Stanford        S02\n",
       "...         ...       ...        ...\n",
       "OC27_002      1       UOP       OC27\n",
       "OC27_003      1       UOP       OC27\n",
       "OC28_001      1       UOP       OC28\n",
       "OC28_002      1       UOP       OC28\n",
       "OC28_003      1       UOP       OC28\n",
       "\n",
       "[142 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_Celldensities = pd.concat([Val_Celldensities, UOP_Celldensities])\n",
    "X_Function = pd.concat([Val_Function, UOP_Function])\n",
    "X_Metavariables = pd.concat([Val_Metavariables, UOP_Metavariables])\n",
    "X_Neighborhood = pd.concat([Val_Neighborhood, UOP_Neighborhood])\n",
    "y = pd.concat([Val_y, UOP_y])\n",
    "y['patient_id'] = y.index.str.split('_').str.get(0)\n",
    "\n",
    "data = {\n",
    "    'Celldensities': X_Celldensities,\n",
    "    'Function': X_Function,\n",
    "    'Metavariables': X_Metavariables,\n",
    "    'Neighborhood': X_Neighborhood,\n",
    "    'Outcome': y\n",
    "}\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>grade</th>\n",
       "      <th>site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S01</td>\n",
       "      <td>1</td>\n",
       "      <td>Stanford</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S02</td>\n",
       "      <td>1</td>\n",
       "      <td>Stanford</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>S03</td>\n",
       "      <td>2</td>\n",
       "      <td>Stanford</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>S04</td>\n",
       "      <td>2</td>\n",
       "      <td>Stanford</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>S05</td>\n",
       "      <td>2</td>\n",
       "      <td>Stanford</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>S06</td>\n",
       "      <td>2</td>\n",
       "      <td>Stanford</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>S07</td>\n",
       "      <td>2</td>\n",
       "      <td>Stanford</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>S08</td>\n",
       "      <td>1</td>\n",
       "      <td>Stanford</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>S09</td>\n",
       "      <td>2</td>\n",
       "      <td>Stanford</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>S10</td>\n",
       "      <td>2</td>\n",
       "      <td>Stanford</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>S11</td>\n",
       "      <td>1</td>\n",
       "      <td>Stanford</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>S12</td>\n",
       "      <td>2</td>\n",
       "      <td>Stanford</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>S13</td>\n",
       "      <td>2</td>\n",
       "      <td>Stanford</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>S14</td>\n",
       "      <td>2</td>\n",
       "      <td>Stanford</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>S15</td>\n",
       "      <td>2</td>\n",
       "      <td>Stanford</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>S16</td>\n",
       "      <td>1</td>\n",
       "      <td>Stanford</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>S17</td>\n",
       "      <td>1</td>\n",
       "      <td>Stanford</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>S18</td>\n",
       "      <td>1</td>\n",
       "      <td>Stanford</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>S19</td>\n",
       "      <td>1</td>\n",
       "      <td>Stanford</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>S20</td>\n",
       "      <td>2</td>\n",
       "      <td>Stanford</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>S21</td>\n",
       "      <td>1</td>\n",
       "      <td>Stanford</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>S22</td>\n",
       "      <td>1</td>\n",
       "      <td>Stanford</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>S23</td>\n",
       "      <td>1</td>\n",
       "      <td>Stanford</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>S24</td>\n",
       "      <td>1</td>\n",
       "      <td>Stanford</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>OC01</td>\n",
       "      <td>1</td>\n",
       "      <td>UOP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>OC02</td>\n",
       "      <td>2</td>\n",
       "      <td>UOP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>OC03</td>\n",
       "      <td>2</td>\n",
       "      <td>UOP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>OC04</td>\n",
       "      <td>2</td>\n",
       "      <td>UOP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>OC05</td>\n",
       "      <td>2</td>\n",
       "      <td>UOP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>OC06</td>\n",
       "      <td>2</td>\n",
       "      <td>UOP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>OC07</td>\n",
       "      <td>2</td>\n",
       "      <td>UOP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>OC08</td>\n",
       "      <td>2</td>\n",
       "      <td>UOP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>OC09</td>\n",
       "      <td>1</td>\n",
       "      <td>UOP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>OC10</td>\n",
       "      <td>1</td>\n",
       "      <td>UOP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>OC11</td>\n",
       "      <td>1</td>\n",
       "      <td>UOP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>OC12</td>\n",
       "      <td>2</td>\n",
       "      <td>UOP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>OC13</td>\n",
       "      <td>1</td>\n",
       "      <td>UOP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>OC17</td>\n",
       "      <td>1</td>\n",
       "      <td>UOP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>OC18</td>\n",
       "      <td>2</td>\n",
       "      <td>UOP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>OC19</td>\n",
       "      <td>1</td>\n",
       "      <td>UOP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>OC20</td>\n",
       "      <td>1</td>\n",
       "      <td>UOP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>OC21</td>\n",
       "      <td>1</td>\n",
       "      <td>UOP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>OC22</td>\n",
       "      <td>2</td>\n",
       "      <td>UOP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>OC24</td>\n",
       "      <td>2</td>\n",
       "      <td>UOP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>OC25</td>\n",
       "      <td>1</td>\n",
       "      <td>UOP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>OC26</td>\n",
       "      <td>1</td>\n",
       "      <td>UOP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>OC27</td>\n",
       "      <td>1</td>\n",
       "      <td>UOP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>OC28</td>\n",
       "      <td>1</td>\n",
       "      <td>UOP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    patient_id  grade      site\n",
       "0          S01      1  Stanford\n",
       "3          S02      1  Stanford\n",
       "6          S03      2  Stanford\n",
       "9          S04      2  Stanford\n",
       "12         S05      2  Stanford\n",
       "15         S06      2  Stanford\n",
       "18         S07      2  Stanford\n",
       "21         S08      1  Stanford\n",
       "24         S09      2  Stanford\n",
       "27         S10      2  Stanford\n",
       "30         S11      1  Stanford\n",
       "33         S12      2  Stanford\n",
       "36         S13      2  Stanford\n",
       "39         S14      2  Stanford\n",
       "42         S15      2  Stanford\n",
       "45         S16      1  Stanford\n",
       "48         S17      1  Stanford\n",
       "51         S18      1  Stanford\n",
       "54         S19      1  Stanford\n",
       "57         S20      2  Stanford\n",
       "59         S21      1  Stanford\n",
       "62         S22      1  Stanford\n",
       "65         S23      1  Stanford\n",
       "68         S24      1  Stanford\n",
       "71        OC01      1       UOP\n",
       "74        OC02      2       UOP\n",
       "76        OC03      2       UOP\n",
       "79        OC04      2       UOP\n",
       "82        OC05      2       UOP\n",
       "85        OC06      2       UOP\n",
       "88        OC07      2       UOP\n",
       "91        OC08      2       UOP\n",
       "94        OC09      1       UOP\n",
       "97        OC10      1       UOP\n",
       "100       OC11      1       UOP\n",
       "103       OC12      2       UOP\n",
       "106       OC13      1       UOP\n",
       "109       OC17      1       UOP\n",
       "112       OC18      2       UOP\n",
       "115       OC19      1       UOP\n",
       "118       OC20      1       UOP\n",
       "121       OC21      1       UOP\n",
       "124       OC22      2       UOP\n",
       "127       OC24      2       UOP\n",
       "130       OC25      1       UOP\n",
       "133       OC26      1       UOP\n",
       "136       OC27      1       UOP\n",
       "139       OC28      1       UOP"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "unique_patients = pd.DataFrame(y['patient_id'].unique(), columns=['patient_id'])\n",
    "unique_patients = unique_patients.merge(y, on='patient_id', how = 'left') \n",
    "unique_patients = unique_patients.drop_duplicates(subset=['patient_id', 'grade', 'site'])\n",
    "unique_patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (28, 3)\n",
      "Validation set shape: (20, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['S01_1', 'S01_2', 'S01_3', 'S02_1', 'S02_2', 'S02_3', 'S03_1', 'S03_2',\n",
       "       'S03_3', 'S04_1', 'S04_2', 'S04_3', 'S06_1', 'S06_2', 'S06_3', 'S08_1',\n",
       "       'S08_2', 'S08_3', 'S09_1', 'S09_2', 'S09_3', 'S11_1', 'S11_2', 'S11_3',\n",
       "       'S12_1', 'S12_2', 'S12_3', 'S13_1', 'S13_2', 'S13_3', 'S15_1', 'S15_2',\n",
       "       'S15_3', 'S16_1', 'S16_2', 'S16_3', 'S18_1', 'S18_2', 'S18_3', 'S23_1',\n",
       "       'S23_2', 'S23_3', 'OC01_001', 'OC01_002', 'OC01_003', 'OC04_001',\n",
       "       'OC04_002', 'OC04_003', 'OC05_001', 'OC05_002', 'OC05_003', 'OC07_001',\n",
       "       'OC07_002', 'OC07_003', 'OC08_001', 'OC08_002', 'OC08_003', 'OC09_001',\n",
       "       'OC09_002', 'OC09_003', 'OC11_001', 'OC11_002', 'OC11_003', 'OC12_001',\n",
       "       'OC12_002', 'OC12_003', 'OC17_001', 'OC17_002', 'OC17_003', 'OC18_001',\n",
       "       'OC18_002', 'OC18_003', 'OC19_001', 'OC19_002', 'OC19_003', 'OC21_001',\n",
       "       'OC21_002', 'OC21_003', 'OC26_001', 'OC26_002', 'OC26_003', 'OC27_001',\n",
       "       'OC27_002', 'OC27_003'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Split the dataframe into training and validation sets\n",
    "train_df, val_df = train_test_split(unique_patients, test_size=0.4, stratify=unique_patients[['site', 'grade']], random_state=1)\n",
    "train_df\n",
    "# Print the shapes of the training and validation sets\n",
    "print(\"Training set shape:\", train_df.shape)\n",
    "print(\"Validation set shape:\", val_df.shape)\n",
    "train_indices = y[y['patient_id'].isin(train_df['patient_id'])].index\n",
    "train_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split each dataframe in the data dictionary into train and test\n",
    "train_data_dict = {}\n",
    "test_data_dict = {}\n",
    "\n",
    "for key, df in data.items():\n",
    "    train_df = df.loc[train_indices]  # Select rows from the dataframe based on train indices\n",
    "    test_df = df.drop(train_indices)  # Drop rows from the dataframe based on train indices\n",
    "    \n",
    "    train_data_dict[key] = train_df\n",
    "    test_data_dict[key] = test_df\n",
    "\n",
    "\n",
    "train_outcome = train_data_dict.pop('Outcome')\n",
    "train_outcome = train_outcome.grade-1\n",
    "test_outcome = test_data_dict.pop('Outcome')\n",
    "test_outcome = test_outcome.grade-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "# Perform Mann-Whitney U test for each numeric variable in the train_data_dict\n",
    "train_results = {}\n",
    "for key, df in train_data_dict.items():\n",
    "    train_results[key] = {}\n",
    "    for column in df.select_dtypes(include=['float64', 'int64']):\n",
    "        x = df[column].dropna()  # Drop NaN values from df[column]\n",
    "        y = train_outcome.loc[df[column].dropna().index]  # Match indices of train_outcome with non-NaN values in df[column]\n",
    "        statistic, p_value = mannwhitneyu(x, y)\n",
    "        train_results[key][column] = {'Statistic': statistic, 'p-value': p_value}\n",
    "\n",
    "# Perform Mann-Whitney U test for each numeric variable in the test_data_dict\n",
    "test_results = {}\n",
    "for key, df in test_data_dict.items():\n",
    "    test_results[key] = {}\n",
    "    for column in df.select_dtypes(include=['float64', 'int64']):\n",
    "        df[column] = df[column].fillna(df[column].mean())\n",
    "        x = df[column].dropna()  # Drop NaN values from df[column]\n",
    "        y = test_outcome.loc[df[column].dropna().index]  # Match indices of test_outcome with non-NaN values in df[column]\n",
    "        statistic, p_value = mannwhitneyu(x, y)\n",
    "        test_results[key][column] = {'Statistic': statistic, 'p-value': p_value}\n",
    "\n",
    "# Create dataframes for train and test results\n",
    "train_results_df = pd.DataFrame(train_results)\n",
    "test_results_df = pd.DataFrame(test_results)\n",
    "\n",
    "# Export train results to CSV\n",
    "train_results_df.to_csv('train_mannwhitneyu_results.csv')\n",
    "\n",
    "# Export test results to CSV\n",
    "test_results_df.to_csv('test_mannwhitneyu_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Outcome'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)\n",
      "\u001b[0;32m/var/folders/yw/jrjtbzm57tbfg8vxk7g41v9h0000gp/T/ipykernel_52502/2559261827.py\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     11\u001b[0m \u001b[0;31m# Iterate over the variables (columns) in the training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_data_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Perform Mann-Whitney U test on the variable and 'grade' column of train_outcome\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Outcome'"
     ]
    }
   ],
   "source": [
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "# Function to perform Mann-Whitney U test and return p-value\n",
    "def perform_mannwhitneyu(data1, data2):\n",
    "    _, p_value = mannwhitneyu(data1, data2)\n",
    "    return p_value\n",
    "\n",
    "# Initialize a list to store the results\n",
    "univariate = []\n",
    "\n",
    "# Iterate over the variables (columns) in the training data\n",
    "for column in train_data_dict[key].columns:\n",
    "    \n",
    "    # Perform Mann-Whitney U test on the variable and 'grade' column of train_outcome\n",
    "    p_value = perform_mannwhitneyu(train_data_dict[key][column], np.array(train_outcome.grade))\n",
    "    \n",
    "    # Add the results to the list\n",
    "    univariate.append([column, p_value])\n",
    "\n",
    "# Create a DataFrame from the results list\n",
    "univariate_df = pd.DataFrame(univariate, columns=['Variable', 'P-value'])\n",
    "\n",
    "# Save the results to a CSV file\n",
    "#univariate_df.to_csv('mannwhitneyu_results.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_folder = \"./RS_MC_RP\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for omic_name, X_omic in train_data_dict.items():\n",
    "    X_omic = remove_low_info_samples(X_omic)\n",
    "    train_data_dict[omic_name] = X_omic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stabl = Stabl(\n",
    "    lambda_name='C',\n",
    "    lambda_grid=np.linspace(0.01, 5, 10),\n",
    "    n_bootstraps=500,\n",
    "    artificial_type=\"random_permutation\",\n",
    "    artificial_proportion=1.,\n",
    "    replace=False,\n",
    "    fdr_threshold_range=np.arange(0.2, 1, 0.01),\n",
    "    sample_fraction=.7,\n",
    "    random_state=111\n",
    " )\n",
    "\n",
    "outer_splitter = RepeatedStratifiedKFold(n_splits=5, n_repeats=20, random_state=1)\n",
    "\n",
    "stability_selection = clone(stabl).set_params(artificial_type=None, hard_threshold=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-omic Training-CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_dict = multi_omic_stabl_cv(\n",
    "    data_dict=train_data_dict,\n",
    "    y=train_outcome,\n",
    "    outer_splitter=outer_splitter,\n",
    "    stabl=stabl,\n",
    "    stability_selection=stability_selection,\n",
    "    task_type=\"binary\",\n",
    "    save_path=Path(result_folder)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiomic Training to derive coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stabl_multi = Stabl(\n",
    "    lambda_grid=np.linspace(0.01, 5, 30),\n",
    "    n_bootstraps=5000,\n",
    "    artificial_proportion=1.,\n",
    "    artificial_type=\"random_permutation\",\n",
    "    hard_threshold=None,\n",
    "    replace=False,\n",
    "    fdr_threshold_range=np.arange(0.2, 1, 0.01),\n",
    "    sample_fraction=.7,\n",
    "    random_state=111\n",
    ")\n",
    "\n",
    "stability_selection = clone(stabl_multi).set_params(artificial_type=None, hard_threshold=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_dict = multi_omic_stabl(\n",
    "    data_dict=train_data_dict,\n",
    "    y=train_outcome,\n",
    "    stabl=stabl_multi,\n",
    "    stability_selection=stability_selection,\n",
    "    task_type=\"binary\",\n",
    "    save_path=Path(result_folder),\n",
    "    X_test=pd.concat(test_data_dict.values(),axis=1),\n",
    "    y_test=test_outcome\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Late fusion lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "late_fusion_lasso_cv(\n",
    "    train_data_dict=train_data_dict,\n",
    "    y=train_outcome,\n",
    "    outer_splitter=outer_splitter,\n",
    "    task_type=\"binary\",\n",
    "    save_path=result_folder,\n",
    "    groups=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features_dict = dict()\n",
    "for model in [\"STABL\", \"EF Lasso\", \"SS 03\", \"SS 05\", \"SS 08\"]:\n",
    "    path = Path(result_folder, \"Training-Validation\", f\"{model} coefficients.csv\")\n",
    "    try:\n",
    "        selected_features_dict[model] = list(pd.read_csv(path, index_col=0).iloc[:, 0].index)\n",
    "    except:\n",
    "        selected_features_dict[model] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_table = compute_features_table(\n",
    "    selected_features_dict,\n",
    "    X_train=pd.concat(train_data_dict.values(), axis=1),\n",
    "    y_train=train_outcome,\n",
    "    task_type=\"binary\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_table.to_csv(Path(result_folder, \"Training-Validation\", \"Table of features.csv\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
